import asyncio
import websockets
import json
import base64
import sounddevice as sd
import numpy as np
from openai import OpenAI

from langdetect import detect

import io
import soundfile as sf
import threading
import queue

import os
from dotenv import load_dotenv
load_dotenv()

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

VOICE_ID = "y2Y5MeVPm6ZQXK64WUui"  # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π voice_id
MODEL_ID = "eleven_flash_v2_5"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∞—É–¥–∏–æ–±—É—Ñ–µ—Ä (FIFO)
audio_queue = queue.Queue()
stream = None

# ===== –ü–æ—Ç–æ–∫ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è =====
def audio_player_worker():
    """–§–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ—á–∞–Ω–∫–æ–≤"""
    global stream
    current_rate = None

    while True:
        data = audio_queue.get()
        if data is None:
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ–ª–∫–∏–µ –∏–ª–∏ –±–∏—Ç—ã–µ —á–∞–Ω–∫–∏
        if len(data) < 500:
            continue


        try:
            with io.BytesIO(data) as f:
                chunk, samplerate = sf.read(f, dtype="float32")

            if stream is None or samplerate != current_rate:
                if stream:
                    stream.stop()
                    stream.close()
                stream = sd.OutputStream(
                    samplerate=samplerate,
                    channels=chunk.shape[1] if chunk.ndim > 1 else 1,
                    dtype="float32"
                )
                stream.start()
                current_rate = samplerate

            stream.write(chunk)

        except Exception as e:
            print(f"[‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ-–ø–æ—Ç–æ–∫–∞]: {e}")

    if stream:
        stream.stop()
        stream.close()


# ===== –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ =====
player_thread = threading.Thread(target=audio_player_worker, daemon=True)
player_thread.start()

# ===== –§—É–Ω–∫—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤ =====
def enqueue_audio_chunk(audio_bytes: bytes):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ—á–∞–Ω–∫ –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è"""
    audio_queue.put(audio_bytes)


# ===== –§–£–ù–ö–¶–ò–Ø: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–ø–ª–∏–∫–∏ =====
def generate_reply(trigger: str) -> str:
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫
    try:
        # lang = detect(trigger)
        lang = "ru"
    except:
        lang = "en"

    if lang.startswith("ru"):
        system_prompt = (
            "–¢—ã ‚Äî –≥–æ–ª–æ—Å —É–º–Ω–æ–≥–æ —ç–ª–µ–∫—Ç—Ä–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –≤ –≥–æ—Ä–æ–¥–µ –ù—É–∞–Ω—É. "
            "–®—É—Ç–æ—á–Ω–æ –æ–ø–∏—à–∏ —Ç–æ, —á—Ç–æ –≤–∏–¥–∏—à—å, "
            "–∫–∞–∫ –±—É–¥—Ç–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–µ—à—å —Å –ø–∞—Å—Å–∞–∂–∏—Ä–∞–º–∏. –ë—É–¥—å –∫—Ä–∞—Ç–æ–∫, –∂–∏–≤–æ–π –∏ –≥–æ–≤–æ—Ä–∏ –ø–æ-—Ä—É—Å—Å–∫–∏."
        )
    else:
        system_prompt = (
            "You are the voice of a smart electric transport vehicle in NUANU city. "
            "Describe what you see humorously, "
            "as if talking to passengers. Be brief and lively in English."
        )

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": trigger},
        ],
    )
    return response.choices[0].message.content.strip()


# ===== STREAMING —Å ElevenLabs =====
async def elevenlabs_stream(text: str):
    uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream-input?model_id={MODEL_ID}"

    async with websockets.connect(uri, ping_interval=None) as ws:
        init_msg = {
            "xi_api_key": ELEVENLABS_API_KEY,
            "text": " ",
            "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
            # –∑–Ω–∞—á–µ–Ω–∏—è >= 50
            "generation_config": {"chunk_length_schedule": [60, 100, 140]},
        }
        await ws.send(json.dumps(init_msg))

        await ws.send(json.dumps({"text": text, "try_trigger_generation": True}))
        await ws.send(json.dumps({"text": ""}))

        print("üéß –û–∑–≤—É—á–∫–∞ –Ω–∞—á–∞–ª–∞—Å—å...\n")
        async for msg in ws:
            try:
                data = json.loads(msg)
            except Exception:
                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ª—é–±—ã–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ñ—Ä–µ–π–º—ã

            audio_b64 = data.get("audio")
            if audio_b64:
                try:
                    audio_bytes = base64.b64decode(audio_b64)
                    enqueue_audio_chunk(audio_bytes)
                except Exception as e:
                    print(f"[‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∞—É–¥–∏–æ]: {e}")

            if data.get("isFinal"):
                print("‚úÖ –ü–æ—Ç–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω.")
                break




# ===== –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ =====
async def main():
    print("–í–≤–µ–¥–∏—Ç–µ —Ç—Ä–∏–≥–≥–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: –∫–∞–º–µ—Ä–∞, –¥–≤–µ —Å–æ–±–∞–∫–∏ —Å–ª–µ–≤–∞):")
    while True:
        trigger = input("> ").strip()
        if not trigger:
            continue
        if trigger.lower() in ["exit", "quit", "stop"]:
            break

        print("ü§ñ –î—É–º–∞—é –Ω–∞–¥ —Ä–µ–ø–ª–∏–∫–æ–π...")
        reply = generate_reply(trigger)
        print(f"üó£Ô∏è –†–µ–ø–ª–∏–∫–∞: {reply}\n")

        await elevenlabs_stream(reply)

if __name__ == "__main__":
    asyncio.run(main())
