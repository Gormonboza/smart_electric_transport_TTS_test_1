"""
âš¡ Fast TTS Pipeline v3: GPT-4o-mini Streaming â†’ ElevenLabs Streaming
=====================================================================
ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ vs tts_test_1.py:
1. GPT-4o-mini streaming â€” Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ´Ñ‘Ñ‚ Ğ² TTS Ğ¿Ğ¾ Ğ¼ĞµÑ€Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸, Ğ½Ğµ Ğ¶Ğ´Ñ‘Ğ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
2. ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ pipeline â€” WebSocket ElevenLabs Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ”Ğ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ GPT
3. chunk_length_schedule ÑĞ½Ğ¸Ğ¶ĞµĞ½ Ğ´Ğ¾ [50] â€” ElevenLabs Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ ÑĞ¸Ğ½Ñ‚ĞµĞ· Ñ€Ğ°Ğ½ÑŒÑˆĞµ
4. Async OpenAI client â€” Ğ½ĞµĞ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒÑÑ‰Ğ¸Ğµ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ñ‹
5. Sentence-based flushing â€” Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² TTS Ğ¿Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼ Ğ´Ğ»Ñ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ€ĞµÑ‡Ğ¸
6. Pre-warmed WebSocket â€” ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğº Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñƒ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´Ğ° Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ°

Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°: TTFA < 1.5Ñ (Ğ±Ñ‹Ğ»Ğ¾ ~4Ñ)

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python tts_fast_pipeline.py                  # Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
    python tts_fast_pipeline.py --benchmark      # Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº
    python tts_fast_pipeline.py --compare        # ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ old vs new
"""

import asyncio
import websockets
import json
import base64
import sounddevice as sd
import numpy as np
import io
import soundfile as sf
import threading
import queue
import time
import os
import sys
from dataclasses import dataclass
from dotenv import load_dotenv
from openai import AsyncOpenAI, OpenAI

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

VOICE_ID = "y2Y5MeVPm6ZQXK64WUui"
MODEL_ID = "eleven_flash_v2_5"
GPT_MODEL = "gpt-4o-mini"

# ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: Ğ°Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚ TTS
TTS_CHUNK_SCHEDULE = [50]  # Ğ‘Ñ‹Ğ»Ğ¾ [60, 100, 140] â€” Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ 50 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
TTS_MIN_BUFFER = 25        # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ¿ĞµÑ€ĞµĞ´ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¾Ğ¹ Ğ² TTS

# Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ (ÑƒĞºĞ¾Ñ€Ğ¾Ñ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ â€” Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² = Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ)
SYSTEM_PROMPT_RU = (
    "Ğ¢Ñ‹ â€” Ğ³Ğ¾Ğ»Ğ¾Ñ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ² Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğµ ĞÑƒĞ°Ğ½Ñƒ. "
    "Ğ¨ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¾Ğ¿Ğ¸ÑˆĞ¸ Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ²Ğ¸Ğ´Ğ¸ÑˆÑŒ, ĞºĞ°Ğº Ğ±ÑƒĞ´Ñ‚Ğ¾ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ°Ñ€Ğ¸Ğ²Ğ°ĞµÑˆÑŒ Ñ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°Ğ¼Ğ¸. "
    "ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ. ĞŸĞ¾-Ñ€ÑƒÑÑĞºĞ¸."
)

SYSTEM_PROMPT_EN = (
    "You are the voice of a smart electric shuttle in NUANU city. "
    "Briefly and humorously describe what you see, as if talking to passengers. "
    "Max 2 sentences."
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class PipelineMetrics:
    """Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°"""
    input_text: str
    generated_text: str = ""
    mode: str = "parallel"

    pipeline_start: float = 0
    ws_connected: float = 0        # WebSocket ElevenLabs Ğ³Ğ¾Ñ‚Ğ¾Ğ²
    llm_first_token: float = 0     # ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¾Ñ‚ GPT
    first_text_to_tts: float = 0   # ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ² TTS
    tts_first_audio: float = 0     # ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾-Ñ‡Ğ°Ğ½Ğº Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½
    llm_end: float = 0             # GPT Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ğ» Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ
    tts_end: float = 0             # TTS Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ğ» ÑĞ¸Ğ½Ñ‚ĞµĞ·
    playback_end: float = 0        # Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡ĞµĞ½Ğ¾

    @property
    def ws_connect_time(self) -> float:
        return self.ws_connected - self.pipeline_start if self.ws_connected else 0

    @property
    def llm_ttft(self) -> float:
        return self.llm_first_token - self.pipeline_start if self.llm_first_token else 0

    @property
    def llm_total(self) -> float:
        return self.llm_end - self.pipeline_start if self.llm_end else 0

    @property
    def time_to_tts_send(self) -> float:
        return self.first_text_to_tts - self.pipeline_start if self.first_text_to_tts else 0

    @property
    def total_ttfa(self) -> float:
        """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°: Ğ¾Ñ‚ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° Ğ´Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ° Ğ¸Ğ· ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸"""
        return self.tts_first_audio - self.pipeline_start if self.tts_first_audio else 0

    @property
    def total_time(self) -> float:
        return self.playback_end - self.pipeline_start if self.playback_end else 0

    def print_report(self):
        print("\n" + "â•" * 65)
        print(f"ğŸ“Š PIPELINE METRICS [{self.mode.upper()}]")
        print("â•" * 65)
        print(f"ğŸ“ Input:  \"{self.input_text}\"")
        print(f"ğŸ—£ï¸ Output: \"{self.generated_text[:80]}{'...' if len(self.generated_text) > 80 else ''}\"")
        print(f"ğŸ“ Length: {len(self.generated_text)} chars")
        print("â”€" * 65)
        print(f"  ğŸ”Œ WebSocket connect:       {self.ws_connect_time*1000:>7.0f} ms")
        print(f"  ğŸ§  LLM first token:         {self.llm_ttft*1000:>7.0f} ms")
        print(f"  ğŸ“¤ First text â†’ TTS:        {self.time_to_tts_send*1000:>7.0f} ms")
        print(f"  ğŸ§  LLM total:               {self.llm_total*1000:>7.0f} ms")
        print("â”€" * 65)
        status = "âœ…" if self.total_ttfa < 1.5 else "âš ï¸" if self.total_ttfa < 2.5 else "âŒ"
        print(f"  âš¡ TOTAL TTFA:              {self.total_ttfa*1000:>7.0f} ms  {status}")
        print(f"  â±ï¸  TOTAL time:             {self.total_time*1000:>7.0f} ms")
        print("â•" * 65)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUDIO PLAYER (Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AudioPlayer:
    """ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ñ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ°"""

    def __init__(self):
        self.audio_queue = queue.Queue()
        self.stream = None
        self.current_rate = None
        self.running = False
        self.thread = None
        self.first_chunk_event = threading.Event()

    def start(self):
        self.running = True
        self.first_chunk_event.clear()
        self.thread = threading.Thread(target=self._worker, daemon=True)
        self.thread.start()

    def stop(self):
        self.running = False
        self.audio_queue.put(None)
        if self.stream:
            try:
                self.stream.stop()
                self.stream.close()
            except Exception:
                pass
            self.stream = None

    def enqueue(self, audio_bytes: bytes):
        self.audio_queue.put(audio_bytes)

    def wait_until_done(self):
        self.audio_queue.join()

    def _worker(self):
        while self.running:
            try:
                data = self.audio_queue.get(timeout=0.1)
            except queue.Empty:
                continue

            if data is None:
                self.audio_queue.task_done()
                break

            if len(data) < 300:
                self.audio_queue.task_done()
                continue

            try:
                with io.BytesIO(data) as f:
                    chunk, samplerate = sf.read(f, dtype="float32")

                if self.stream is None or samplerate != self.current_rate:
                    if self.stream:
                        self.stream.stop()
                        self.stream.close()
                    self.stream = sd.OutputStream(
                        samplerate=samplerate,
                        channels=chunk.shape[1] if chunk.ndim > 1 else 1,
                        dtype="float32",
                        blocksize=1024,  # ĞœĞµĞ½ÑŒÑˆĞ¸Ğ¹ Ğ±ÑƒÑ„ĞµÑ€ = Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ°
                    )
                    self.stream.start()
                    self.current_rate = samplerate

                self.stream.write(chunk)

                if not self.first_chunk_event.is_set():
                    self.first_chunk_event.set()

            except Exception as e:
                print(f"[âš ï¸ Audio]: {e}")

            self.audio_queue.task_done()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OLD PIPELINE (ĞºĞ°Ğº Ğ±Ñ‹Ğ»Ğ¾ â€” Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OldPipeline:
    """ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¸Ğ· tts_test_1.py"""

    def __init__(self):
        self.client = OpenAI(api_key=OPENAI_API_KEY)

    def generate_reply(self, trigger: str) -> str:
        """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ â€” Ğ¶Ğ´Ñ‘Ğ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚"""
        response = self.client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT_RU},
                {"role": "user", "content": trigger},
            ],
        )
        return response.choices[0].message.content.strip()

    async def run(self, trigger: str, metrics: PipelineMetrics, player: AudioPlayer):
        """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½"""
        metrics.pipeline_start = time.time()
        metrics.mode = "sequential"

        # Ğ¨Ğ°Ğ³ 1: Ğ¶Ğ´Ñ‘Ğ¼ Ğ’Ğ•Ğ¡Ğ¬ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ GPT
        reply = self.generate_reply(trigger)
        metrics.generated_text = reply
        metrics.llm_first_token = time.time()
        metrics.llm_end = time.time()

        # Ğ¨Ğ°Ğ³ 2: Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ²ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ² ElevenLabs
        uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream-input?model_id={MODEL_ID}"

        async with websockets.connect(uri, ping_interval=None) as ws:
            metrics.ws_connected = time.time()

            init_msg = {
                "xi_api_key": ELEVENLABS_API_KEY,
                "text": " ",
                "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
                "generation_config": {"chunk_length_schedule": [60, 100, 140]},
            }
            await ws.send(json.dumps(init_msg))

            metrics.first_text_to_tts = time.time()
            await ws.send(json.dumps({"text": reply, "try_trigger_generation": True}))
            await ws.send(json.dumps({"text": ""}))

            first_audio = False
            async for msg in ws:
                try:
                    data = json.loads(msg)
                except Exception:
                    continue

                audio_b64 = data.get("audio")
                if audio_b64:
                    audio_bytes = base64.b64decode(audio_b64)
                    if not first_audio:
                        metrics.tts_first_audio = time.time()
                        first_audio = True
                    player.enqueue(audio_bytes)

                if data.get("isFinal"):
                    metrics.tts_end = time.time()
                    break


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NEW PIPELINE (Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FastPipeline:
    """
    ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½:
    GPT-4o-mini streaming â†’ Ğ±ÑƒÑ„ĞµÑ€ Ğ¿Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼ â†’ ElevenLabs WebSocket streaming

    ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ¾Ñ‚ OldPipeline:
    1. WebSocket Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ ĞŸĞ•Ğ Ğ’Ğ«Ğœ (Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾ Ñ GPT Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼)
    2. GPT ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹, Ğ¼Ñ‹ Ğ½Ğ°ĞºĞ°Ğ¿Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼
    3. ĞšĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ ÑÑ€Ğ°Ğ·Ñƒ ÑƒÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ² ElevenLabs
    4. chunk_length_schedule = [50] Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ°
    """

    def __init__(self):
        self.async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

    async def run(self, trigger: str, metrics: PipelineMetrics, player: AudioPlayer):
        """ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½"""
        metrics.pipeline_start = time.time()
        metrics.mode = "parallel"

        uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream-input?model_id={MODEL_ID}"

        async with websockets.connect(uri, ping_interval=None) as ws:
            metrics.ws_connected = time.time()

            # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ElevenLabs WebSocket
            init_msg = {
                "xi_api_key": ELEVENLABS_API_KEY,
                "text": " ",
                "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
                "generation_config": {"chunk_length_schedule": TTS_CHUNK_SCHEDULE},
            }
            await ws.send(json.dumps(init_msg))

            # Ğ¤Ğ»Ğ°Ğ³Ğ¸
            first_text_sent = False
            first_audio_received = False
            full_text = ""

            async def send_llm_to_tts():
                """Ğ¡Ñ‚Ñ€Ğ¸Ğ¼Ğ¸Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ GPT â†’ Ğ½Ğ°ĞºĞ°Ğ¿Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ â†’ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ² TTS Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚ÑĞ¼"""
                nonlocal first_text_sent, full_text

                buffer = ""
                sent_chars = 0

                stream = await self.async_client.chat.completions.create(
                    model=GPT_MODEL,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT_RU},
                        {"role": "user", "content": trigger},
                    ],
                    stream=True,
                    max_tokens=100,  # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸
                )

                first_token = False

                async for chunk in stream:
                    delta = chunk.choices[0].delta
                    if delta.content:
                        token = delta.content

                        if not first_token:
                            metrics.llm_first_token = time.time()
                            first_token = True

                        buffer += token
                        full_text += token

                        # Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸:
                        # 1. ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚ â€” ĞºĞ°Ğº Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ°Ğ±Ñ€Ğ°Ğ»Ğ¸ TTS_MIN_BUFFER ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
                        # 2. Ğ”Ğ°Ğ»ĞµĞµ â€” Ğ¿Ğ¾ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹ (. ! ? , ;) Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾ 80+ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
                        should_flush = False

                        if not first_text_sent and len(buffer) >= TTS_MIN_BUFFER:
                            should_flush = True
                        elif first_text_sent:
                            # Ğ˜Ñ‰ĞµĞ¼ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
                            for delim in ['. ', '! ', '? ', ', ', '; ', 'â€” ']:
                                if delim in buffer:
                                    should_flush = True
                                    break
                            # Ğ˜Ğ»Ğ¸ ĞµÑĞ»Ğ¸ Ğ±ÑƒÑ„ĞµÑ€ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹
                            if len(buffer) >= 80:
                                should_flush = True

                        if should_flush and buffer.strip():
                            await ws.send(json.dumps({
                                "text": buffer,
                                "try_trigger_generation": True
                            }))
                            sent_chars += len(buffer)

                            if not first_text_sent:
                                metrics.first_text_to_tts = time.time()
                                first_text_sent = True

                            buffer = ""

                metrics.llm_end = time.time()

                # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ğº
                if buffer.strip():
                    await ws.send(json.dumps({
                        "text": buffer,
                        "try_trigger_generation": True
                    }))

                # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
                await ws.send(json.dumps({"text": ""}))

                metrics.generated_text = full_text.strip()

            async def receive_audio():
                """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾-Ñ‡Ğ°Ğ½ĞºĞ¸ Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ² Ğ¿Ğ»ĞµĞµÑ€"""
                nonlocal first_audio_received

                async for msg in ws:
                    try:
                        data = json.loads(msg)
                    except Exception:
                        continue

                    audio_b64 = data.get("audio")
                    if audio_b64:
                        audio_bytes = base64.b64decode(audio_b64)
                        if not first_audio_received:
                            metrics.tts_first_audio = time.time()
                            first_audio_received = True
                        player.enqueue(audio_bytes)

                    if data.get("isFinal"):
                        metrics.tts_end = time.time()
                        break

            # Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾: Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ° + Ğ¿Ñ€Ğ¸Ñ‘Ğ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾
            await asyncio.gather(send_llm_to_tts(), receive_audio())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ¢Ğ•Ğ¡Ğ¢ĞĞ’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run_single(pipeline, trigger: str, play_audio: bool = True) -> PipelineMetrics:
    """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ°"""
    metrics = PipelineMetrics(input_text=trigger)
    player = AudioPlayer()

    if play_audio:
        player.start()

    await pipeline.run(trigger, metrics, player)

    if play_audio:
        player.wait_until_done()
        await asyncio.sleep(0.3)
        player.stop()

    metrics.playback_end = time.time()
    return metrics


async def run_benchmark():
    """Ğ‘ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°"""
    triggers = [
        "ĞºĞ°Ğ¼ĞµÑ€Ğ°, Ğ´Ğ²Ğµ ÑĞ¾Ğ±Ğ°ĞºĞ¸ ÑĞ»ĞµĞ²Ğ° Ğ½Ğ° Ğ¾Ğ±Ğ¾Ñ‡Ğ¸Ğ½Ğµ",
        "Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ñ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¾Ğ², Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº 8, Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€ÑƒÑÑ‚ Ñ…Ñ€Ğ°Ğ¼",
        "ÑĞ¿Ñ€Ğ°Ğ²Ğ° Ğ¼Ğ¾Ñ‚Ğ¾Ñ†Ğ¸ĞºĞ» Ğ¾Ğ±Ğ³Ğ¾Ğ½ÑĞµÑ‚, Ğ½Ğ° Ğ½Ñ‘Ğ¼ Ğ´Ğ²Ğ¾Ğµ Ğ±ĞµĞ· ÑˆĞ»ĞµĞ¼Ğ¾Ğ²",
        "Ğ¿Ñ€Ğ¾ĞµĞ·Ğ¶Ğ°ĞµĞ¼ Ñ€Ğ¸ÑĞ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ñ, ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾",
        "Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‘ÑÑ‚Ğ¾Ğº, ÑĞ»ĞµĞ²Ğ° ĞµĞ´ĞµÑ‚ Ğ³Ñ€ÑƒĞ·Ğ¾Ğ²Ğ¸Ğº Ñ ĞºĞ¾ĞºĞ¾ÑĞ°Ğ¼Ğ¸",
    ]

    print("=" * 65)
    print("ğŸš€ FAST PIPELINE BENCHMARK: GPT-4o-mini â†’ ElevenLabs")
    print("=" * 65)

    if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:
        print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ OPENAI_API_KEY Ğ¸ ELEVENLABS_API_KEY Ğ² .env")
        return

    pipeline = FastPipeline()
    results = []

    for trigger in triggers:
        print(f"\nğŸ¯ \"{trigger}\"")
        try:
            metrics = await run_single(pipeline, trigger, play_audio=True)
            metrics.print_report()
            results.append(metrics)
            await asyncio.sleep(1.0)
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()

    if results:
        print("\n" + "=" * 65)
        print("ğŸ“ˆ Ğ¡Ğ’ĞĞ”ĞšĞ")
        print("=" * 65)
        ttfa = [r.total_ttfa * 1000 for r in results]
        llm_ttft = [r.llm_ttft * 1000 for r in results]
        ws_times = [r.ws_connect_time * 1000 for r in results]
        print(f"  WebSocket connect:   avg={sum(ws_times)/len(ws_times):.0f}ms")
        print(f"  LLM first token:     avg={sum(llm_ttft)/len(llm_ttft):.0f}ms")
        print(f"  TOTAL TTFA:          avg={sum(ttfa)/len(ttfa):.0f}ms")
        print(f"                       min={min(ttfa):.0f}ms")
        print(f"                       max={max(ttfa):.0f}ms")
        ok = sum(1 for t in ttfa if t < 1500)
        print(f"\n  âœ… TTFA < 1.5s:     {ok}/{len(ttfa)}")
        ok2 = sum(1 for t in ttfa if t < 2000)
        print(f"  âœ… TTFA < 2.0s:     {ok2}/{len(ttfa)}")


async def run_comparison():
    """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ€Ğ¾Ğ³Ğ¾ Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°"""
    triggers = [
        "ĞºĞ°Ğ¼ĞµÑ€Ğ°, Ğ´Ğ²Ğµ ÑĞ¾Ğ±Ğ°ĞºĞ¸ ÑĞ»ĞµĞ²Ğ°",
        "Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ñ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¾Ğ², Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€ÑƒÑÑ‚ Ñ…Ñ€Ğ°Ğ¼",
        "ÑĞ¿Ñ€Ğ°Ğ²Ğ° ÑĞºÑƒÑ‚ĞµÑ€ Ğ¾Ğ±Ğ³Ğ¾Ğ½ÑĞµÑ‚",
    ]

    print("=" * 65)
    print("ğŸ”¬ COMPARISON: Sequential (old) vs Parallel (new)")
    print("=" * 65)

    if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:
        print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ OPENAI_API_KEY Ğ¸ ELEVENLABS_API_KEY Ğ² .env")
        return

    old = OldPipeline()
    new = FastPipeline()

    old_results = []
    new_results = []

    for trigger in triggers:
        print(f"\n{'='*65}")
        print(f"ğŸ¯ \"{trigger}\"")

        # Old
        print("\n  â–¶ï¸ SEQUENTIAL (old)...")
        try:
            m_old = await run_single(old, trigger, play_audio=True)
            m_old.print_report()
            old_results.append(m_old)
        except Exception as e:
            print(f"  âŒ {e}")

        await asyncio.sleep(1.5)

        # New
        print("\n  â–¶ï¸ PARALLEL (new)...")
        try:
            m_new = await run_single(new, trigger, play_audio=True)
            m_new.print_report()
            new_results.append(m_new)
        except Exception as e:
            print(f"  âŒ {e}")

        await asyncio.sleep(1.5)

    # Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°
    if old_results and new_results:
        print("\n" + "=" * 65)
        print("ğŸ“Š Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ•")
        print("=" * 65)
        old_ttfa = [r.total_ttfa * 1000 for r in old_results]
        new_ttfa = [r.total_ttfa * 1000 for r in new_results]
        avg_old = sum(old_ttfa) / len(old_ttfa)
        avg_new = sum(new_ttfa) / len(new_ttfa)
        improvement = (1 - avg_new / avg_old) * 100 if avg_old > 0 else 0

        print(f"\n  {'ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ°':<25} {'Old (seq)':>12} {'New (par)':>12} {'Speedup':>12}")
        print("  " + "â”€" * 61)
        print(f"  {'TTFA avg':<25} {avg_old:>10.0f}ms {avg_new:>10.0f}ms {improvement:>10.0f}%")
        print(f"  {'TTFA min':<25} {min(old_ttfa):>10.0f}ms {min(new_ttfa):>10.0f}ms")
        print(f"  {'TTFA max':<25} {max(old_ttfa):>10.0f}ms {max(new_ttfa):>10.0f}ms")
        print(f"\n  ğŸ† Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: {improvement:.0f}%")


async def interactive_mode():
    """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¼ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ¼"""
    print("=" * 65)
    print("âš¡ FAST PIPELINE â€” Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼")
    print("=" * 65)
    print("GPT-4o-mini streaming â†’ ElevenLabs streaming")
    print("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ (exit Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°):\n")

    if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:
        print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ OPENAI_API_KEY Ğ¸ ELEVENLABS_API_KEY Ğ² .env")
        return

    pipeline = FastPipeline()

    while True:
        try:
            trigger = input("> ").strip()
            if not trigger:
                continue
            if trigger.lower() in ["exit", "quit", "q"]:
                break

            metrics = await run_single(pipeline, trigger, play_audio=True)
            metrics.print_report()

        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()

    print("\nğŸ‘‹ Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!")


def main():
    if len(sys.argv) > 1:
        if sys.argv[1] == "--benchmark":
            asyncio.run(run_benchmark())
        elif sys.argv[1] == "--compare":
            asyncio.run(run_comparison())
        else:
            print("Usage: python tts_fast_pipeline.py [--benchmark|--compare]")
    else:
        asyncio.run(interactive_mode())


if __name__ == "__main__":
    main()
