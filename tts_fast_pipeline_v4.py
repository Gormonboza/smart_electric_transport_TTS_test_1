"""
âš¡ Fast TTS Pipeline v4: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ latency
=============================================
Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ vs v3:
1. TTS_MIN_BUFFER ÑĞ½Ğ¸Ğ¶ĞµĞ½ 25 â†’ 15 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² (Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ¿ĞµÑ€Ğ²Ğ°Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ°)
2. temperature=0 (Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ sampling GPT)
3. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ ÑĞ¾ĞºÑ€Ğ°Ñ‰Ñ‘Ğ½ Ğ´Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼Ğ° (Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² = Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ TTFT)
4. Persistent WebSocket pool â€” WS Ğº ElevenLabs Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ Ğ—ĞĞ ĞĞĞ•Ğ•, Ğ´Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
5. OpenAI connection pre-warm â€” Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ·Ğ° ÑÑ‡Ñ‘Ñ‚ keep-alive
6. chunk_length_schedule ÑĞ½Ğ¸Ğ¶ĞµĞ½ [50] â†’ [40] â€” ĞµÑ‰Ñ‘ Ğ°Ğ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½ĞµĞµ

Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°: TTFA < 1.2Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python tts_fast_pipeline_v4.py                  # Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
    python tts_fast_pipeline_v4.py --benchmark      # Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº
    python tts_fast_pipeline_v4.py --compare        # ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ v3 vs v4
"""

import asyncio
import websockets
import json
import base64
import sounddevice as sd
import numpy as np
import io
import soundfile as sf
import threading
import queue
import time
import os
import sys
from dataclasses import dataclass
from dotenv import load_dotenv
from openai import AsyncOpenAI, OpenAI

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

VOICE_ID = "y2Y5MeVPm6ZQXK64WUui"
MODEL_ID = "eleven_flash_v2_5"
GPT_MODEL = "gpt-4o-mini"

# â”€â”€ v4 Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ â”€â”€
TTS_CHUNK_SCHEDULE = [50]   # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ ElevenLabs = 50
TTS_MIN_BUFFER = 15         # v3: 25  â†’ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚ ÑƒÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ñ€Ğ°Ğ½ÑŒÑˆĞµ

# ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ ÑĞ¶Ğ°Ñ‚ â€” ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½ = Ğ·Ğ°Ğ´ĞµÑ€Ğ¶ĞºĞ° TTFT
SYSTEM_PROMPT_RU = "Ğ“Ğ¾Ğ»Ğ¾Ñ ÑˆĞ°Ñ‚Ñ‚Ğ»Ğ° NUANU. Ğ¨ÑƒÑ‚ĞºĞ° Ğ¿Ñ€Ğ¾ ÑƒĞ²Ğ¸Ğ´ĞµĞ½Ğ½Ğ¾Ğµ, 1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾-Ñ€ÑƒÑÑĞºĞ¸."
SYSTEM_PROMPT_EN = "NUANU shuttle voice. Joke about what you see, 1-2 sentences."

ELEVENLABS_URI = f"wss://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream-input?model_id={MODEL_ID}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class PipelineMetrics:
    input_text: str
    generated_text: str = ""
    mode: str = "v4"

    pipeline_start: float = 0
    ws_connected: float = 0
    llm_first_token: float = 0
    first_text_to_tts: float = 0
    tts_first_audio: float = 0
    llm_end: float = 0
    tts_end: float = 0
    playback_end: float = 0
    ws_was_preconnected: bool = False  # True ĞµÑĞ»Ğ¸ WS Ğ±Ñ‹Ğ» Ğ¸Ğ· Ğ¿ÑƒĞ»Ğ°

    @property
    def ws_connect_time(self) -> float:
        return self.ws_connected - self.pipeline_start if self.ws_connected else 0

    @property
    def llm_ttft(self) -> float:
        return self.llm_first_token - self.pipeline_start if self.llm_first_token else 0

    @property
    def llm_total(self) -> float:
        return self.llm_end - self.pipeline_start if self.llm_end else 0

    @property
    def time_to_tts_send(self) -> float:
        return self.first_text_to_tts - self.pipeline_start if self.first_text_to_tts else 0

    @property
    def total_ttfa(self) -> float:
        return self.tts_first_audio - self.pipeline_start if self.tts_first_audio else 0

    @property
    def total_time(self) -> float:
        return self.playback_end - self.pipeline_start if self.playback_end else 0

    def print_report(self):
        print("\n" + "â•" * 65)
        print(f"ğŸ“Š PIPELINE METRICS [{self.mode.upper()}]")
        print("â•" * 65)
        print(f"ğŸ“ Input:  \"{self.input_text}\"")
        print(f"ğŸ—£ï¸ Output: \"{self.generated_text[:80]}{'...' if len(self.generated_text) > 80 else ''}\"")
        print(f"ğŸ“ Length: {len(self.generated_text)} chars")
        print("â”€" * 65)
        ws_note = " (pre-connected â™»ï¸)" if self.ws_was_preconnected else ""
        print(f"  ğŸ”Œ WebSocket connect:       {self.ws_connect_time*1000:>7.0f} ms{ws_note}")
        print(f"  ğŸ§  LLM first token:         {self.llm_ttft*1000:>7.0f} ms")
        print(f"  ğŸ“¤ First text â†’ TTS:        {self.time_to_tts_send*1000:>7.0f} ms")
        print(f"  ğŸ§  LLM total:               {self.llm_total*1000:>7.0f} ms")
        print("â”€" * 65)
        status = "âœ…" if self.total_ttfa < 1.2 else "âš ï¸" if self.total_ttfa < 2.0 else "âŒ"
        print(f"  âš¡ TOTAL TTFA:              {self.total_ttfa*1000:>7.0f} ms  {status}")
        print(f"  â±ï¸  TOTAL time:             {self.total_time*1000:>7.0f} ms")
        print("â•" * 65)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUDIO PLAYER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AudioPlayer:
    def __init__(self):
        self.audio_queue = queue.Queue()
        self.stream = None
        self.current_rate = None
        self.running = False
        self.thread = None

    def start(self):
        self.running = True
        self.thread = threading.Thread(target=self._worker, daemon=True)
        self.thread.start()

    def stop(self):
        self.running = False
        self.audio_queue.put(None)
        if self.stream:
            try:
                self.stream.stop()
                self.stream.close()
            except Exception:
                pass
            self.stream = None

    def enqueue(self, audio_bytes: bytes):
        self.audio_queue.put(audio_bytes)

    def wait_until_done(self):
        self.audio_queue.join()

    def _worker(self):
        while self.running:
            try:
                data = self.audio_queue.get(timeout=0.1)
            except queue.Empty:
                continue

            if data is None:
                self.audio_queue.task_done()
                break

            if len(data) < 300:
                self.audio_queue.task_done()
                continue

            try:
                with io.BytesIO(data) as f:
                    chunk, samplerate = sf.read(f, dtype="float32")

                if self.stream is None or samplerate != self.current_rate:
                    if self.stream:
                        self.stream.stop()
                        self.stream.close()
                    self.stream = sd.OutputStream(
                        samplerate=samplerate,
                        channels=chunk.shape[1] if chunk.ndim > 1 else 1,
                        dtype="float32",
                        blocksize=1024,
                    )
                    self.stream.start()
                    self.current_rate = samplerate

                self.stream.write(chunk)
            except Exception as e:
                print(f"[âš ï¸ Audio]: {e}")

            self.audio_queue.task_done()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ELEVENLABS WEBSOCKET POOL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ElevenLabsPool:
    """
    ĞŸÑƒĞ» pre-connected WebSocket'Ğ¾Ğ² Ğº ElevenLabs.

    ĞŸĞ¾ÑĞ»Ğµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° ÑÑ€Ğ°Ğ·Ñƒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Ñ„Ğ¾Ğ½Ğµ,
    Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ WS ÑƒĞ¶Ğµ Ğ±Ñ‹Ğ» Ğ³Ğ¾Ñ‚Ğ¾Ğ².
    Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‚ ~150ms Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ ĞºÑ€Ğ¾Ğ¼Ğµ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾.
    """

    def __init__(self):
        self._ready_ws = None
        self._ready_event = asyncio.Event()
        self._preconnecting = False

    async def _create_connection(self):
        """ĞÑ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ WebSocket Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ init"""
        ws = await websockets.connect(ELEVENLABS_URI, ping_interval=None)
        init_msg = {
            "xi_api_key": ELEVENLABS_API_KEY,
            "text": " ",
            "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
            "generation_config": {"chunk_length_schedule": TTS_CHUNK_SCHEDULE},
        }
        await ws.send(json.dumps(init_msg))
        return ws

    async def preconnect(self):
        """ĞÑ‚ĞºÑ€Ñ‹Ñ‚ÑŒ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ñ€Ğ°Ğ½ĞµĞµ (Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ² Ñ„Ğ¾Ğ½Ğµ)"""
        if self._preconnecting:
            return
        self._preconnecting = True
        try:
            self._ready_ws = await self._create_connection()
            self._ready_event.set()
        except Exception as e:
            print(f"[âš ï¸ Preconnect failed]: {e}")
            self._ready_ws = None
        finally:
            self._preconnecting = False

    async def get_ws(self) -> tuple:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ WebSocket.
        Returns: (ws, was_preconnected: bool)
        """
        if self._ready_ws is not None:
            ws = self._ready_ws
            self._ready_ws = None
            self._ready_event.clear()
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ WS ĞµÑ‰Ñ‘ Ğ¶Ğ¸Ğ²
            try:
                # ĞŸĞ¸Ğ½Ğ³ Ñ‡ĞµÑ€ĞµĞ· Ğ¿ÑƒÑÑ‚Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
                if ws.open:
                    return ws, True
            except Exception:
                pass

        # ĞĞµÑ‚ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ â€” ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹
        ws = await self._create_connection()
        return ws, False

    async def schedule_preconnect(self):
        """Ğ—Ğ°Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ„Ğ¾Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
        asyncio.create_task(self.preconnect())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPENAI WARMER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class OpenAIWarmer:
    """
    Pre-warm OpenAI HTTP connection.
    ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº OpenAI Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½ĞµĞµ Ğ¸Ğ·-Ğ·Ğ° DNS + TCP + TLS.
    Ğ”ĞµĞ»Ğ°ĞµĞ¼ dummy-Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ keep-alive ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾.
    """

    def __init__(self, client: AsyncOpenAI):
        self.client = client
        self._warmed = False

    async def warmup(self):
        if self._warmed:
            return
        print("ğŸ”¥ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² OpenAI connection...")
        t = time.time()
        try:
            # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ»Ñ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ
            resp = await self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[{"role": "user", "content": "hi"}],
                max_tokens=1,
                temperature=0,
            )
            self._warmed = True
            print(f"âœ… OpenAI Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑ‚ Ğ·Ğ° {(time.time()-t)*1000:.0f}ms")
        except Exception as e:
            print(f"âš ï¸ OpenAI warmup failed: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# V3 PIPELINE (Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PipelineV3:
    """v3 pipeline â€” Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ (Ğ±ĞµĞ· persistent WS, Ğ±ĞµĞ· warmup)"""

    def __init__(self):
        self.async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

    async def run(self, trigger: str, metrics: PipelineMetrics, player: AudioPlayer):
        metrics.pipeline_start = time.time()
        metrics.mode = "v3"

        async with websockets.connect(ELEVENLABS_URI, ping_interval=None) as ws:
            metrics.ws_connected = time.time()

            init_msg = {
                "xi_api_key": ELEVENLABS_API_KEY,
                "text": " ",
                "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
                "generation_config": {"chunk_length_schedule": [50]},  # v3 value
            }
            await ws.send(json.dumps(init_msg))

            first_text_sent = False
            first_audio_received = False
            full_text = ""
            V3_MIN_BUFFER = 25  # v3 value

            async def send_llm_to_tts():
                nonlocal first_text_sent, full_text
                buffer = ""

                stream = await self.async_client.chat.completions.create(
                    model=GPT_MODEL,
                    messages=[
                        {"role": "system", "content": (
                            "Ğ¢Ñ‹ â€” Ğ³Ğ¾Ğ»Ğ¾Ñ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»ĞµĞºÑ‚Ñ€Ğ¾Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ğ² Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğµ ĞÑƒĞ°Ğ½Ñƒ. "
                            "Ğ¨ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¾Ğ¿Ğ¸ÑˆĞ¸ Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ²Ğ¸Ğ´Ğ¸ÑˆÑŒ, ĞºĞ°Ğº Ğ±ÑƒĞ´Ñ‚Ğ¾ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ°Ñ€Ğ¸Ğ²Ğ°ĞµÑˆÑŒ Ñ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°Ğ¼Ğ¸. "
                            "ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ. ĞŸĞ¾-Ñ€ÑƒÑÑĞºĞ¸."
                        )},
                        {"role": "user", "content": trigger},
                    ],
                    stream=True,
                    max_tokens=100,
                )

                first_token = False

                async for chunk in stream:
                    delta = chunk.choices[0].delta
                    if delta.content:
                        token = delta.content
                        if not first_token:
                            metrics.llm_first_token = time.time()
                            first_token = True
                        buffer += token
                        full_text += token

                        should_flush = False
                        if not first_text_sent and len(buffer) >= V3_MIN_BUFFER:
                            should_flush = True
                        elif first_text_sent:
                            for delim in ['. ', '! ', '? ', ', ', '; ', 'â€” ']:
                                if delim in buffer:
                                    should_flush = True
                                    break
                            if len(buffer) >= 80:
                                should_flush = True

                        if should_flush and buffer.strip():
                            await ws.send(json.dumps({"text": buffer, "try_trigger_generation": True}))
                            if not first_text_sent:
                                metrics.first_text_to_tts = time.time()
                                first_text_sent = True
                            buffer = ""

                metrics.llm_end = time.time()
                if buffer.strip():
                    await ws.send(json.dumps({"text": buffer, "try_trigger_generation": True}))
                await ws.send(json.dumps({"text": ""}))
                metrics.generated_text = full_text.strip()

            async def receive_audio():
                nonlocal first_audio_received
                async for msg in ws:
                    try:
                        data = json.loads(msg)
                    except Exception:
                        continue
                    audio_b64 = data.get("audio")
                    if audio_b64:
                        audio_bytes = base64.b64decode(audio_b64)
                        if not first_audio_received:
                            metrics.tts_first_audio = time.time()
                            first_audio_received = True
                        player.enqueue(audio_bytes)
                    if data.get("isFinal"):
                        metrics.tts_end = time.time()
                        break

            await asyncio.gather(send_llm_to_tts(), receive_audio())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# V4 PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PipelineV4:
    """
    v4 pipeline â€” Ğ²ÑĞµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:
    - Persistent WebSocket pool
    - Pre-warmed OpenAI connection
    - Shorter prompt, temp=0
    - TTS_MIN_BUFFER=15, chunk_schedule=[40]
    """

    def __init__(self):
        self.async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        self.warmer = OpenAIWarmer(self.async_client)
        self.ws_pool = ElevenLabsPool()

    async def warmup(self):
        """ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ²ÑĞµÑ… ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹"""
        await self.warmer.warmup()
        print("ğŸ”Œ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² ElevenLabs WebSocket...")
        t = time.time()
        await self.ws_pool.preconnect()
        print(f"âœ… ElevenLabs WebSocket Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğ·Ğ° {(time.time()-t)*1000:.0f}ms")

    async def run(self, trigger: str, metrics: PipelineMetrics, player: AudioPlayer):
        metrics.pipeline_start = time.time()
        metrics.mode = "v4"

        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ WS (Ğ¸Ğ· Ğ¿ÑƒĞ»Ğ° Ğ¸Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹)
        ws, was_preconnected = await self.ws_pool.get_ws()
        metrics.ws_connected = time.time()
        metrics.ws_was_preconnected = was_preconnected

        try:
            first_text_sent = False
            first_audio_received = False
            full_text = ""

            async def send_llm_to_tts():
                nonlocal first_text_sent, full_text
                buffer = ""

                stream = await self.async_client.chat.completions.create(
                    model=GPT_MODEL,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT_RU},
                        {"role": "user", "content": trigger},
                    ],
                    stream=True,
                    max_tokens=80,      # v4: ĞµÑ‰Ñ‘ ĞºĞ¾Ñ€Ğ¾Ñ‡Ğµ (Ğ±Ñ‹Ğ»Ğ¾ 100)
                    temperature=0,       # v4: Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ = Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ
                )

                first_token = False

                async for chunk in stream:
                    delta = chunk.choices[0].delta
                    if delta.content:
                        token = delta.content

                        if not first_token:
                            metrics.llm_first_token = time.time()
                            first_token = True

                        buffer += token
                        full_text += token

                        should_flush = False

                        if not first_text_sent and len(buffer) >= TTS_MIN_BUFFER:
                            should_flush = True
                        elif first_text_sent:
                            for delim in ['. ', '! ', '? ', ', ', '; ']:
                                if delim in buffer:
                                    should_flush = True
                                    break
                            if len(buffer) >= 60:  # v4: ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¾ Ñ 80
                                should_flush = True

                        if should_flush and buffer.strip():
                            await ws.send(json.dumps({
                                "text": buffer,
                                "try_trigger_generation": True,
                            }))
                            if not first_text_sent:
                                metrics.first_text_to_tts = time.time()
                                first_text_sent = True
                            buffer = ""

                metrics.llm_end = time.time()

                if buffer.strip():
                    await ws.send(json.dumps({
                        "text": buffer,
                        "try_trigger_generation": True,
                    }))

                await ws.send(json.dumps({"text": ""}))
                metrics.generated_text = full_text.strip()

            async def receive_audio():
                nonlocal first_audio_received
                async for msg in ws:
                    try:
                        data = json.loads(msg)
                    except Exception:
                        continue

                    audio_b64 = data.get("audio")
                    if audio_b64:
                        audio_bytes = base64.b64decode(audio_b64)
                        if not first_audio_received:
                            metrics.tts_first_audio = time.time()
                            first_audio_received = True
                        player.enqueue(audio_bytes)

                    if data.get("isFinal"):
                        metrics.tts_end = time.time()
                        break

            await asyncio.gather(send_llm_to_tts(), receive_audio())

        finally:
            # Ğ—Ğ°ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ WS
            try:
                await ws.close()
            except Exception:
                pass

            # Ğ¡Ñ€Ğ°Ğ·Ñƒ Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ WS Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
            await self.ws_pool.schedule_preconnect()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run_single(pipeline, trigger: str, play_audio: bool = True) -> PipelineMetrics:
    metrics = PipelineMetrics(input_text=trigger)
    player = AudioPlayer()

    if play_audio:
        player.start()

    await pipeline.run(trigger, metrics, player)

    if play_audio:
        player.wait_until_done()
        await asyncio.sleep(0.3)
        player.stop()

    metrics.playback_end = time.time()
    return metrics


async def run_benchmark():
    triggers = [
        "ĞºĞ°Ğ¼ĞµÑ€Ğ°, Ğ´Ğ²Ğµ ÑĞ¾Ğ±Ğ°ĞºĞ¸ ÑĞ»ĞµĞ²Ğ° Ğ½Ğ° Ğ¾Ğ±Ğ¾Ñ‡Ğ¸Ğ½Ğµ",
        "Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ñ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¾Ğ², Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº 8, Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€ÑƒÑÑ‚ Ñ…Ñ€Ğ°Ğ¼",
        "ÑĞ¿Ñ€Ğ°Ğ²Ğ° Ğ¼Ğ¾Ñ‚Ğ¾Ñ†Ğ¸ĞºĞ» Ğ¾Ğ±Ğ³Ğ¾Ğ½ÑĞµÑ‚, Ğ½Ğ° Ğ½Ñ‘Ğ¼ Ğ´Ğ²Ğ¾Ğµ Ğ±ĞµĞ· ÑˆĞ»ĞµĞ¼Ğ¾Ğ²",
        "Ğ¿Ñ€Ğ¾ĞµĞ·Ğ¶Ğ°ĞµĞ¼ Ñ€Ğ¸ÑĞ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ñ, ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾",
        "Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‘ÑÑ‚Ğ¾Ğº, ÑĞ»ĞµĞ²Ğ° ĞµĞ´ĞµÑ‚ Ğ³Ñ€ÑƒĞ·Ğ¾Ğ²Ğ¸Ğº Ñ ĞºĞ¾ĞºĞ¾ÑĞ°Ğ¼Ğ¸",
    ]

    print("=" * 65)
    print("ğŸš€ FAST PIPELINE v4 BENCHMARK")
    print("=" * 65)

    if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:
        print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ OPENAI_API_KEY Ğ¸ ELEVENLABS_API_KEY Ğ² .env")
        return

    pipeline = PipelineV4()
    await pipeline.warmup()

    results = []
    for trigger in triggers:
        print(f"\nğŸ¯ \"{trigger}\"")
        try:
            metrics = await run_single(pipeline, trigger, play_audio=True)
            metrics.print_report()
            results.append(metrics)
            await asyncio.sleep(1.0)
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()

    if results:
        print("\n" + "=" * 65)
        print("ğŸ“ˆ Ğ¡Ğ’ĞĞ”ĞšĞ v4")
        print("=" * 65)
        ttfa = [r.total_ttfa * 1000 for r in results]
        llm_ttft = [r.llm_ttft * 1000 for r in results]
        ws_times = [r.ws_connect_time * 1000 for r in results]
        preconn = sum(1 for r in results if r.ws_was_preconnected)
        print(f"  WebSocket connect:   avg={sum(ws_times)/len(ws_times):.0f}ms  (pre-connected: {preconn}/{len(results)})")
        print(f"  LLM first token:     avg={sum(llm_ttft)/len(llm_ttft):.0f}ms")
        print(f"  TOTAL TTFA:          avg={sum(ttfa)/len(ttfa):.0f}ms")
        print(f"                       min={min(ttfa):.0f}ms")
        print(f"                       max={max(ttfa):.0f}ms")
        ok = sum(1 for t in ttfa if t < 1200)
        print(f"\n  âœ… TTFA < 1.2s:     {ok}/{len(ttfa)}")
        ok2 = sum(1 for t in ttfa if t < 1500)
        print(f"  âœ… TTFA < 1.5s:     {ok2}/{len(ttfa)}")


async def run_comparison():
    """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ v3 vs v4"""
    triggers = [
        "ĞºĞ°Ğ¼ĞµÑ€Ğ°, Ğ´Ğ²Ğµ ÑĞ¾Ğ±Ğ°ĞºĞ¸ ÑĞ»ĞµĞ²Ğ°",
        "Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ñ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¾Ğ², Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ€ÑƒÑÑ‚ Ñ…Ñ€Ğ°Ğ¼",
        "ÑĞ¿Ñ€Ğ°Ğ²Ğ° ÑĞºÑƒÑ‚ĞµÑ€ Ğ¾Ğ±Ğ³Ğ¾Ğ½ÑĞµÑ‚",
        "Ğ´ĞµÑ€ĞµĞ²Ğ¾ ÑƒĞ¿Ğ°Ğ»Ğ¾ Ğ½Ğ° Ğ´Ğ¾Ñ€Ğ¾Ğ³Ñƒ",
        "Ñ€ÑĞ´Ğ¾Ğ¼ ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ²Ğ¾Ğ´Ğ¾Ğ¿Ğ°Ğ´",
    ]

    print("=" * 65)
    print("ğŸ”¬ COMPARISON: v3 vs v4")
    print("=" * 65)

    if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:
        print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ OPENAI_API_KEY Ğ¸ ELEVENLABS_API_KEY Ğ² .env")
        return

    v3 = PipelineV3()
    v4 = PipelineV4()
    await v4.warmup()

    v3_results = []
    v4_results = []

    for trigger in triggers:
        print(f"\n{'='*65}")
        print(f"ğŸ¯ \"{trigger}\"")

        # v3
        print("\n  â–¶ï¸ v3...")
        try:
            m = await run_single(v3, trigger, play_audio=True)
            m.print_report()
            v3_results.append(m)
        except Exception as e:
            print(f"  âŒ {e}")

        await asyncio.sleep(1.5)

        # v4
        print("\n  â–¶ï¸ v4...")
        try:
            m = await run_single(v4, trigger, play_audio=True)
            m.print_report()
            v4_results.append(m)
        except Exception as e:
            print(f"  âŒ {e}")

        await asyncio.sleep(1.5)

    if v3_results and v4_results:
        print("\n" + "=" * 65)
        print("ğŸ“Š Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• v3 vs v4")
        print("=" * 65)
        v3_ttfa = [r.total_ttfa * 1000 for r in v3_results]
        v4_ttfa = [r.total_ttfa * 1000 for r in v4_results]
        avg_v3 = sum(v3_ttfa) / len(v3_ttfa)
        avg_v4 = sum(v4_ttfa) / len(v4_ttfa)
        improvement = (1 - avg_v4 / avg_v3) * 100 if avg_v3 > 0 else 0

        v3_llm = [r.llm_ttft * 1000 for r in v3_results]
        v4_llm = [r.llm_ttft * 1000 for r in v4_results]
        v3_ws = [r.ws_connect_time * 1000 for r in v3_results]
        v4_ws = [r.ws_connect_time * 1000 for r in v4_results]

        print(f"\n  {'ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ°':<25} {'v3':>12} {'v4':>12} {'Î”':>12}")
        print("  " + "â”€" * 61)
        print(f"  {'WS connect avg':<25} {sum(v3_ws)/len(v3_ws):>10.0f}ms {sum(v4_ws)/len(v4_ws):>10.0f}ms {sum(v4_ws)/len(v4_ws)-sum(v3_ws)/len(v3_ws):>+10.0f}ms")
        print(f"  {'LLM TTFT avg':<25} {sum(v3_llm)/len(v3_llm):>10.0f}ms {sum(v4_llm)/len(v4_llm):>10.0f}ms {sum(v4_llm)/len(v4_llm)-sum(v3_llm)/len(v3_llm):>+10.0f}ms")
        print(f"  {'TTFA avg':<25} {avg_v3:>10.0f}ms {avg_v4:>10.0f}ms {avg_v4-avg_v3:>+10.0f}ms")
        print(f"  {'TTFA min':<25} {min(v3_ttfa):>10.0f}ms {min(v4_ttfa):>10.0f}ms")
        print(f"  {'TTFA max':<25} {max(v3_ttfa):>10.0f}ms {max(v4_ttfa):>10.0f}ms")
        print(f"\n  ğŸ† Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ TTFA: {improvement:.0f}%")


async def interactive_mode():
    print("=" * 65)
    print("âš¡ FAST PIPELINE v4 â€” Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼")
    print("=" * 65)
    print("ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: persistent WS, pre-warm, temp=0, short prompt")
    print("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€ (exit Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°):\n")

    if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:
        print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ OPENAI_API_KEY Ğ¸ ELEVENLABS_API_KEY Ğ² .env")
        return

    pipeline = PipelineV4()
    await pipeline.warmup()

    while True:
        try:
            trigger = input("> ").strip()
            if not trigger:
                continue
            if trigger.lower() in ["exit", "quit", "q"]:
                break

            metrics = await run_single(pipeline, trigger, play_audio=True)
            metrics.print_report()

        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()

    print("\nğŸ‘‹ Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!")


def main():
    if len(sys.argv) > 1:
        if sys.argv[1] == "--benchmark":
            asyncio.run(run_benchmark())
        elif sys.argv[1] == "--compare":
            asyncio.run(run_comparison())
        else:
            print("Usage: python tts_fast_pipeline_v4.py [--benchmark|--compare]")
    else:
        asyncio.run(interactive_mode())


if __name__ == "__main__":
    main()
