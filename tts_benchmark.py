"""
TTS Benchmark: Vikhr 12B + ElevenLabs Streaming
Ğ˜Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ TTFA (Time-to-First-Audio) Ğ¸ Ğ¾Ğ±Ñ‰ĞµĞ¹ latency

Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
    pip install websockets sounddevice soundfile ollama python-dotenv

ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°:
    Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ .env Ñ„Ğ°Ğ¹Ğ» Ñ ELEVENLABS_API_KEY=Ğ²Ğ°Ñˆ_ĞºĞ»ÑÑ‡
    
Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python tts_benchmark.py
"""

import asyncio
import websockets
import json
import base64
import sounddevice as sd
import numpy as np
import io
import soundfile as sf
import threading
import queue
import time
import os
from dataclasses import dataclass
from typing import Optional
from dotenv import load_dotenv

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
VOICE_ID = "y2Y5MeVPm6ZQXK64WUui"  # Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ³Ğ¾Ğ»Ğ¾Ñ
MODEL_ID = "eleven_flash_v2_5"      # Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ

# Ollama
OLLAMA_MODEL = "rscr/vikhr_nemo_12b:Q4_K_M"
OLLAMA_URL = "http://localhost:11434"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class BenchmarkResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ·Ğ°Ğ¼ĞµÑ€Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
    input_text: str
    generated_text: str
    
    # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ° (Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…)
    llm_start: float = 0
    llm_first_token: float = 0
    llm_end: float = 0
    tts_start: float = 0
    tts_first_audio: float = 0
    tts_end: float = 0
    playback_end: float = 0
    
    @property
    def llm_ttft(self) -> float:
        """LLM Time-to-First-Token"""
        return self.llm_first_token - self.llm_start
    
    @property
    def llm_total(self) -> float:
        """LLM Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸"""
        return self.llm_end - self.llm_start
    
    @property
    def tts_ttfa(self) -> float:
        """TTS Time-to-First-Audio"""
        return self.tts_first_audio - self.tts_start
    
    @property
    def tts_total(self) -> float:
        """TTS Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ"""
        return self.tts_end - self.tts_start
    
    @property
    def total_ttfa(self) -> float:
        """ĞĞ±Ñ‰Ğ¸Ğ¹ TTFA (Ğ¾Ñ‚ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ´Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°)"""
        return self.tts_first_audio - self.llm_start
    
    @property
    def total_time(self) -> float:
        """ĞĞ±Ñ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ° Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ"""
        return self.playback_end - self.llm_start
    
    def print_report(self):
        """Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°"""
        print("\n" + "â•" * 60)
        print("ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« Ğ‘Ğ•ĞĞ§ĞœĞĞ ĞšĞ")
        print("â•" * 60)
        print(f"ğŸ“ Ğ’Ñ…Ğ¾Ğ´: \"{self.input_text}\"")
        print(f"ğŸ—£ï¸ ĞÑ‚Ğ²ĞµÑ‚: \"{self.generated_text}\"")
        print(f"ğŸ“ Ğ”Ğ»Ğ¸Ğ½Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {len(self.generated_text)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
        print("-" * 60)
        print(f"ğŸ§  LLM Time-to-First-Token:  {self.llm_ttft*1000:>7.0f} ms")
        print(f"ğŸ§  LLM Total Generation:     {self.llm_total*1000:>7.0f} ms")
        print("-" * 60)
        print(f"ğŸ”Š TTS Time-to-First-Audio:  {self.tts_ttfa*1000:>7.0f} ms")
        print(f"ğŸ”Š TTS Total Synthesis:      {self.tts_total*1000:>7.0f} ms")
        print("-" * 60)
        print(f"âš¡ TOTAL TTFA:               {self.total_ttfa*1000:>7.0f} ms  {'âœ…' if self.total_ttfa < 0.5 else 'âš ï¸'}")
        print(f"â±ï¸ TOTAL Time:               {self.total_time*1000:>7.0f} ms")
        print("â•" * 60)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUDIO PLAYER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AudioPlayer:
    """ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾"""
    
    def __init__(self):
        self.audio_queue = queue.Queue()
        self.stream = None
        self.current_rate = None
        self.running = False
        self.thread = None
        self.first_chunk_played = threading.Event()
        
    def start(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ñ„Ğ¾Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°"""
        self.running = True
        self.first_chunk_played.clear()
        self.thread = threading.Thread(target=self._worker, daemon=True)
        self.thread.start()
        
    def stop(self):
        """ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ"""
        self.running = False
        self.audio_queue.put(None)  # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None
            
    def enqueue(self, audio_bytes: bytes):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡Ğ°Ğ½Ğº Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ"""
        self.audio_queue.put(audio_bytes)
        
    def wait_until_done(self):
        """Ğ–Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ"""
        self.audio_queue.join()
        
    def _worker(self):
        """Ğ¤Ğ¾Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ"""
        while self.running:
            try:
                data = self.audio_queue.get(timeout=0.1)
            except queue.Empty:
                continue
                
            if data is None:
                self.audio_queue.task_done()
                break
                
            # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¼ĞµĞ»ĞºĞ¸Ğµ Ñ‡Ğ°Ğ½ĞºĞ¸
            if len(data) < 500:
                self.audio_queue.task_done()
                continue
                
            try:
                with io.BytesIO(data) as f:
                    chunk, samplerate = sf.read(f, dtype="float32")
                    
                if self.stream is None or samplerate != self.current_rate:
                    if self.stream:
                        self.stream.stop()
                        self.stream.close()
                    self.stream = sd.OutputStream(
                        samplerate=samplerate,
                        channels=chunk.shape[1] if chunk.ndim > 1 else 1,
                        dtype="float32"
                    )
                    self.stream.start()
                    self.current_rate = samplerate
                    
                self.stream.write(chunk)
                
                # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ñ‡Ñ‚Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ñ‡Ğ°Ğ½Ğº Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´Ñ‘Ğ½
                if not self.first_chunk_played.is_set():
                    self.first_chunk_played.set()
                    
            except Exception as e:
                print(f"[âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°ÑƒĞ´Ğ¸Ğ¾]: {e}")
                
            self.audio_queue.task_done()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM RESPONSE GENERATOR (Vikhr 12B)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResponseGenerator:
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Vikhr 12B"""
    
    SYSTEM_PROMPT = """Ğ¢Ñ‹ â€” Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾Ğ¼Ğ° Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ’Ğ¸Ğ»Ğ»Ğ°.
Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ (Ğ´Ğ¾ 15 ÑĞ»Ğ¾Ğ²) ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹.
ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾, Ğ¿Ğ¾ Ğ´ĞµĞ»Ñƒ, Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ğ¾. ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸.

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹ â†’ "Ğ’ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹!"
ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ â†’ "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾, Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ²ĞµÑ‚."
ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: Ğ·Ğ°ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ â†’ "Ğ—Ğ°ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ. Ğ§Ñ‚Ğ¾-Ğ½Ğ¸Ğ±ÑƒĞ´ÑŒ ĞµÑ‰Ñ‘?"
ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: ĞºĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° â†’ "Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ¿Ğ»ÑÑ Ğ¿ÑÑ‚Ğ½Ğ°Ğ´Ñ†Ğ°Ñ‚ÑŒ, ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ¾."
ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: Ğ²ĞºĞ»ÑÑ‡Ğ¸ ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½ĞµÑ€ Ğ½Ğ° 22 Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ° â†’ "Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ñ Ğ´Ğ²Ğ°Ğ´Ñ†Ğ°Ñ‚ÑŒ Ğ´Ğ²Ğ° Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ°."
"""

    def __init__(self):
        try:
            import ollama
            self.client = ollama
        except ImportError:
            raise ImportError("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ ollama: pip install ollama")
    
    def generate(self, command: str, result: BenchmarkResult) -> str:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (Ğ±ĞµĞ· ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³Ğ°, Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°)"""
        result.llm_start = time.time()
        
        response = self.client.chat(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": f"ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: {command}"}
            ],
            options={"temperature": 0.7, "num_predict": 50}
        )
        
        result.llm_first_token = time.time()  # Ğ”Ğ»Ñ non-streaming ÑÑ‚Ğ¾ Ñ‚Ğ¾ Ğ¶Ğµ Ñ‡Ñ‚Ğ¾ Ğ¸ end
        result.llm_end = time.time()
        
        return response["message"]["content"].strip()
    
    def generate_streaming(self, command: str, result: BenchmarkResult):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° ÑĞ¾ ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³Ğ¾Ğ¼ (Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)"""
        result.llm_start = time.time()
        first_token = False
        
        stream = self.client.chat(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": f"ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: {command}"}
            ],
            options={"temperature": 0.7, "num_predict": 50},
            stream=True
        )
        
        full_response = ""
        for chunk in stream:
            token = chunk["message"]["content"]
            full_response += token
            
            if not first_token:
                result.llm_first_token = time.time()
                first_token = True
                
            yield token
            
        result.llm_end = time.time()
        result.generated_text = full_response.strip()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ELEVENLABS TTS STREAMING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ElevenLabsTTS:
    """ElevenLabs WebSocket TTS"""
    
    def __init__(self, api_key: str, voice_id: str, model_id: str):
        self.api_key = api_key
        self.voice_id = voice_id
        self.model_id = model_id
        
    async def synthesize(self, text: str, result: BenchmarkResult, player: AudioPlayer):
        """Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ñ€ĞµÑ‡Ğ¸ Ñ‡ĞµÑ€ĞµĞ· WebSocket"""
        uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream-input?model_id={self.model_id}"
        
        result.tts_start = time.time()
        first_audio = False
        
        async with websockets.connect(uri, ping_interval=None) as ws:
            # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
            init_msg = {
                "xi_api_key": self.api_key,
                "text": " ",
                "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
                "generation_config": {"chunk_length_schedule": [60, 100, 140]},
            }
            await ws.send(json.dumps(init_msg))
            
            # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ°
            await ws.send(json.dumps({"text": text, "try_trigger_generation": True}))
            await ws.send(json.dumps({"text": ""}))  # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
            
            # ĞŸÑ€Ğ¸Ñ‘Ğ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²
            async for msg in ws:
                try:
                    data = json.loads(msg)
                except:
                    continue
                    
                audio_b64 = data.get("audio")
                if audio_b64:
                    try:
                        audio_bytes = base64.b64decode(audio_b64)
                        
                        if not first_audio:
                            result.tts_first_audio = time.time()
                            first_audio = True
                            print(f"ğŸ”Š ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡Ğ°Ğ½Ğº Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½!")
                            
                        player.enqueue(audio_bytes)
                        
                    except Exception as e:
                        print(f"[âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ]: {e}")
                        
                if data.get("isFinal"):
                    result.tts_end = time.time()
                    break


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ‘Ğ•ĞĞ§ĞœĞĞ Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run_benchmark(command: str, play_audio: bool = True) -> BenchmarkResult:
    """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ°"""
    result = BenchmarkResult(input_text=command, generated_text="")
    
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    generator = ResponseGenerator()
    tts = ElevenLabsTTS(ELEVENLABS_API_KEY, VOICE_ID, MODEL_ID)
    player = AudioPlayer()
    
    print(f"\nğŸ¯ Ğ¢ĞµÑÑ‚: \"{command}\"")
    print("-" * 40)
    
    # 1. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
    print("ğŸ§  Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Vikhr 12B...")
    response_text = generator.generate(command, result)
    result.generated_text = response_text
    print(f"   â†’ \"{response_text}\" ({result.llm_total*1000:.0f}ms)")
    
    # 2. TTS
    print("ğŸ”Š Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ñ€ĞµÑ‡Ğ¸ Ñ‡ĞµÑ€ĞµĞ· ElevenLabs...")
    if play_audio:
        player.start()
        
    await tts.synthesize(response_text, result, player)
    
    # 3. Ğ–Ğ´Ñ‘Ğ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ
    if play_audio:
        print("ğŸ§ Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ...")
        player.wait_until_done()
        # ĞĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ°Ñ Ğ¿Ğ°ÑƒĞ·Ğ° Ğ´Ğ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
        await asyncio.sleep(0.5)
        player.stop()
        
    result.playback_end = time.time()
    
    return result


async def run_full_benchmark():
    """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº Ñ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ñ‚ĞµÑÑ‚Ğ°Ğ¼Ğ¸"""
    
    test_commands = [
        "Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹",
        "Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚",
        "ĞºĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°",
        "Ğ·Ğ°ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ",
        "Ğ²ĞºĞ»ÑÑ‡Ğ¸ ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½ĞµÑ€ Ğ½Ğ° 22 Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ°",
    ]
    
    print("=" * 60)
    print("ğŸš€ TTS BENCHMARK: Vikhr 12B + ElevenLabs")
    print("=" * 60)
    
    if not ELEVENLABS_API_KEY:
        print("âŒ ELEVENLABS_API_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² .env")
        return
        
    results = []
    
    for cmd in test_commands:
        try:
            result = await run_benchmark(cmd, play_audio=True)
            result.print_report()
            results.append(result)
            
            # ĞŸĞ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ‚ĞµÑÑ‚Ğ°Ğ¼Ğ¸
            await asyncio.sleep(1.0)
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            import traceback
            traceback.print_exc()
    
    # Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°
    if results:
        print("\n" + "=" * 60)
        print("ğŸ“ˆ Ğ¡Ğ’ĞĞ”ĞšĞ")
        print("=" * 60)
        
        ttfa_values = [r.total_ttfa * 1000 for r in results]
        llm_values = [r.llm_total * 1000 for r in results]
        tts_ttfa_values = [r.tts_ttfa * 1000 for r in results]
        
        print(f"LLM Generation:     avg={sum(llm_values)/len(llm_values):.0f}ms")
        print(f"TTS TTFA:           avg={sum(tts_ttfa_values)/len(tts_ttfa_values):.0f}ms")
        print(f"TOTAL TTFA:         avg={sum(ttfa_values)/len(ttfa_values):.0f}ms")
        print(f"                    min={min(ttfa_values):.0f}ms")
        print(f"                    max={max(ttfa_values):.0f}ms")
        
        success_rate = sum(1 for t in ttfa_values if t < 500) / len(ttfa_values) * 100
        print(f"\nâœ… TTFA < 500ms:    {success_rate:.0f}% ({sum(1 for t in ttfa_values if t < 500)}/{len(ttfa_values)})")


async def interactive_mode():
    """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼"""
    print("=" * 60)
    print("ğŸ™ï¸ Ğ˜ĞĞ¢Ğ•Ğ ĞĞšĞ¢Ğ˜Ğ’ĞĞ«Ğ™ Ğ Ğ•Ğ–Ğ˜Ğœ")
    print("=" * 60)
    print("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ Ğ´Ğ»Ñ Ğ¾Ğ·Ğ²ÑƒÑ‡ĞºĞ¸ (exit Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°):\n")
    
    if not ELEVENLABS_API_KEY:
        print("âŒ ELEVENLABS_API_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² .env")
        return
    
    while True:
        try:
            command = input("> ").strip()
            if not command:
                continue
            if command.lower() in ["exit", "quit", "q"]:
                break
                
            result = await run_benchmark(command, play_audio=True)
            result.print_report()
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            
    print("\nğŸ‘‹ Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!")


def main():
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--interactive":
        asyncio.run(interactive_mode())
    else:
        asyncio.run(run_full_benchmark())


if __name__ == "__main__":
    main()
