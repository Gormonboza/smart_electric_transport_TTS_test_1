"""
TTS Benchmark V2: ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ pipeline
Vikhr 12B (streaming) + ElevenLabs (streaming)

ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:
1. ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² LLM Ğ¿ĞµÑ€ĞµĞ´ Ñ‚ĞµÑÑ‚Ğ°Ğ¼Ğ¸
2. ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ pipeline: LLM Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ â†’ Ğ±ÑƒÑ„ĞµÑ€ â†’ TTS
3. TTS Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ ~30 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
4. Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞµĞ½ chunk_length_schedule Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‚Ğ°

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python tts_benchmark_v2.py
    python tts_benchmark_v2.py --interactive
    python tts_benchmark_v2.py --compare  # ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ sequential vs parallel
"""

import asyncio
import websockets
import json
import base64
import sounddevice as sd
import numpy as np
import io
import soundfile as sf
import threading
import queue
import time
import os
from dataclasses import dataclass, field
from typing import Optional, AsyncIterator
from dotenv import load_dotenv

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
VOICE_ID = "y2Y5MeVPm6ZQXK64WUui"
MODEL_ID = "eleven_flash_v2_5"

OLLAMA_MODEL = "rscr/vikhr_nemo_12b:Q4_K_M"

# ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±ÑƒÑ„ĞµÑ€ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° TTS
TTS_MIN_CHARS = 30  # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ TTS Ğ¿Ğ¾ÑĞ»Ğµ 30 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
TTS_CHUNK_SCHEDULE = [50, 80, 120]  # Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¾ Ñ [60, 100, 140]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class BenchmarkResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ·Ğ°Ğ¼ĞµÑ€Ğ°"""
    input_text: str
    generated_text: str = ""
    mode: str = "sequential"  # sequential Ğ¸Ğ»Ğ¸ parallel
    
    pipeline_start: float = 0
    llm_first_token: float = 0
    llm_end: float = 0
    tts_start: float = 0
    tts_first_audio: float = 0
    tts_end: float = 0
    playback_end: float = 0
    
    @property
    def llm_ttft(self) -> float:
        return self.llm_first_token - self.pipeline_start if self.llm_first_token else 0
    
    @property
    def llm_total(self) -> float:
        return self.llm_end - self.pipeline_start if self.llm_end else 0
    
    @property
    def tts_ttfa(self) -> float:
        return self.tts_first_audio - self.tts_start if self.tts_first_audio and self.tts_start else 0
    
    @property
    def total_ttfa(self) -> float:
        """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°: Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° Ğ´Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°"""
        return self.tts_first_audio - self.pipeline_start if self.tts_first_audio else 0
    
    @property
    def total_time(self) -> float:
        return self.playback_end - self.pipeline_start if self.playback_end else 0
    
    def print_report(self):
        print("\n" + "â•" * 60)
        print(f"ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« [{self.mode.upper()}]")
        print("â•" * 60)
        print(f"ğŸ“ Ğ’Ñ…Ğ¾Ğ´: \"{self.input_text}\"")
        print(f"ğŸ—£ï¸ ĞÑ‚Ğ²ĞµÑ‚: \"{self.generated_text}\"")
        print(f"ğŸ“ Ğ”Ğ»Ğ¸Ğ½Ğ°: {len(self.generated_text)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
        print("-" * 60)
        print(f"ğŸ§  LLM First Token:          {self.llm_ttft*1000:>7.0f} ms")
        print(f"ğŸ§  LLM Total:                {self.llm_total*1000:>7.0f} ms")
        print("-" * 60)
        print(f"ğŸ”Š TTS Start (Ğ¾Ñ‚ pipeline):  {(self.tts_start - self.pipeline_start)*1000:>7.0f} ms")
        print(f"ğŸ”Š TTS TTFA (Ğ¾Ñ‚ tts_start):  {self.tts_ttfa*1000:>7.0f} ms")
        print("-" * 60)
        status = "âœ…" if self.total_ttfa < 0.5 else "âš ï¸" if self.total_ttfa < 1.0 else "âŒ"
        print(f"âš¡ TOTAL TTFA:               {self.total_ttfa*1000:>7.0f} ms  {status}")
        print(f"â±ï¸ TOTAL Time:               {self.total_time*1000:>7.0f} ms")
        print("â•" * 60)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUDIO PLAYER (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AudioPlayer:
    def __init__(self):
        self.audio_queue = queue.Queue()
        self.stream = None
        self.current_rate = None
        self.running = False
        self.thread = None
        
    def start(self):
        self.running = True
        self.thread = threading.Thread(target=self._worker, daemon=True)
        self.thread.start()
        
    def stop(self):
        self.running = False
        self.audio_queue.put(None)
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None
            
    def enqueue(self, audio_bytes: bytes):
        self.audio_queue.put(audio_bytes)
        
    def wait_until_done(self):
        self.audio_queue.join()
        
    def _worker(self):
        while self.running:
            try:
                data = self.audio_queue.get(timeout=0.1)
            except queue.Empty:
                continue
                
            if data is None:
                self.audio_queue.task_done()
                break
                
            if len(data) < 500:
                self.audio_queue.task_done()
                continue
                
            try:
                with io.BytesIO(data) as f:
                    chunk, samplerate = sf.read(f, dtype="float32")
                    
                if self.stream is None or samplerate != self.current_rate:
                    if self.stream:
                        self.stream.stop()
                        self.stream.close()
                    self.stream = sd.OutputStream(
                        samplerate=samplerate,
                        channels=chunk.shape[1] if chunk.ndim > 1 else 1,
                        dtype="float32"
                    )
                    self.stream.start()
                    self.current_rate = samplerate
                    
                self.stream.write(chunk)
            except Exception as e:
                print(f"[âš ï¸ Audio error]: {e}")
                
            self.audio_queue.task_done()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM STREAMING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class StreamingLLM:
    """Vikhr 12B ÑĞ¾ ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²"""
    
    SYSTEM_PROMPT = """Ğ¢Ñ‹ â€” Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾Ğ¼Ğ° Ğ’Ğ¸Ğ»Ğ»Ğ°.
Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ (Ğ´Ğ¾ 15 ÑĞ»Ğ¾Ğ²) Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹.
ĞšÑ€Ğ°Ñ‚ĞºĞ¾, Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ğ¾. Ğ‘ĞµĞ· ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸.

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹ â†’ Ğ’ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹!
Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ â†’ Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾, Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ°Ñ ÑĞ²ĞµÑ‚.
Ğ·Ğ°ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ â†’ Ğ—Ğ°ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ.
ĞºĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° â†’ Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ¿Ğ»ÑÑ Ğ¿ÑÑ‚Ğ½Ğ°Ğ´Ñ†Ğ°Ñ‚ÑŒ, ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ¾.
Ğ²ĞºĞ»ÑÑ‡Ğ¸ ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½ĞµÑ€ Ğ½Ğ° 22 â†’ Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°Ñ Ğ´Ğ²Ğ°Ğ´Ñ†Ğ°Ñ‚ÑŒ Ğ´Ğ²Ğ° Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ°."""

    def __init__(self):
        import ollama
        self.client = ollama
        self._warmed_up = False
        
    def warmup(self):
        """ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
        if self._warmed_up:
            return
        print("ğŸ”¥ ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² LLM...")
        start = time.time()
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
        self.client.chat(
            model=OLLAMA_MODEL,
            messages=[{"role": "user", "content": "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚"}],
            options={"num_predict": 5}
        )
        print(f"âœ… LLM Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑ‚ Ğ·Ğ° {time.time()-start:.1f}s")
        self._warmed_up = True
        
    def generate_stream(self, command: str, result: BenchmarkResult):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¾ ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³Ğ¾Ğ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²"""
        first_token = False
        full_text = ""
        
        stream = self.client.chat(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": f"ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: {command}"}
            ],
            options={"temperature": 0.7, "num_predict": 50},
            stream=True
        )
        
        for chunk in stream:
            token = chunk["message"]["content"]
            full_text += token
            
            if not first_token:
                result.llm_first_token = time.time()
                first_token = True
                
            yield token
            
        result.llm_end = time.time()
        result.generated_text = full_text.strip()
        
    def generate_sync(self, command: str, result: BenchmarkResult) -> str:
        """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ (Ğ´Ğ»Ñ sequential Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°)"""
        response = self.client.chat(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": f"ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: {command}"}
            ],
            options={"temperature": 0.7, "num_predict": 50}
        )
        result.llm_first_token = time.time()
        result.llm_end = time.time()
        result.generated_text = response["message"]["content"].strip()
        return result.generated_text


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ELEVENLABS TTS STREAMING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ElevenLabsTTS:
    def __init__(self):
        self.api_key = ELEVENLABS_API_KEY
        self.voice_id = VOICE_ID
        self.model_id = MODEL_ID
        
    async def synthesize_text(self, text: str, result: BenchmarkResult, player: AudioPlayer):
        """Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°"""
        uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream-input?model_id={self.model_id}"
        
        result.tts_start = time.time()
        first_audio = False
        
        async with websockets.connect(uri, ping_interval=None) as ws:
            init_msg = {
                "xi_api_key": self.api_key,
                "text": " ",
                "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
                "generation_config": {"chunk_length_schedule": TTS_CHUNK_SCHEDULE},
            }
            await ws.send(json.dumps(init_msg))
            await ws.send(json.dumps({"text": text, "try_trigger_generation": True}))
            await ws.send(json.dumps({"text": ""}))
            
            async for msg in ws:
                try:
                    data = json.loads(msg)
                except:
                    continue
                    
                audio_b64 = data.get("audio")
                if audio_b64:
                    audio_bytes = base64.b64decode(audio_b64)
                    if not first_audio:
                        result.tts_first_audio = time.time()
                        first_audio = True
                    player.enqueue(audio_bytes)
                    
                if data.get("isFinal"):
                    result.tts_end = time.time()
                    break

    async def synthesize_streaming(
        self, 
        text_queue: asyncio.Queue, 
        result: BenchmarkResult, 
        player: AudioPlayer
    ):
        """
        Ğ¡Ñ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ÑĞ¸Ğ½Ñ‚ĞµĞ·: Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚ÑĞ¼ Ğ¸Ğ· Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ¸.
        ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ ÑĞ¸Ğ½Ñ‚ĞµĞ· Ğ¿Ğ¾ÑĞ»Ğµ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ TTS_MIN_CHARS ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ².
        """
        uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream-input?model_id={self.model_id}"
        
        first_audio = False
        buffer = ""
        tts_started = False
        
        async with websockets.connect(uri, ping_interval=None) as ws:
            # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ WebSocket
            init_msg = {
                "xi_api_key": self.api_key,
                "text": " ",
                "voice_settings": {"stability": 0.4, "similarity_boost": 0.9},
                "generation_config": {"chunk_length_schedule": TTS_CHUNK_SCHEDULE},
            }
            await ws.send(json.dumps(init_msg))
            
            async def send_text():
                """ĞšĞ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² TTS"""
                nonlocal buffer, tts_started
                
                while True:
                    item = await text_queue.get()
                    
                    if item is None:  # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
                        # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾ÑÑ‚Ğ°Ğ²ÑˆĞ¸Ğ¹ÑÑ Ğ±ÑƒÑ„ĞµÑ€
                        if buffer:
                            await ws.send(json.dumps({"text": buffer, "try_trigger_generation": True}))
                        await ws.send(json.dumps({"text": ""}))  # Ğ¤Ğ¸Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
                        break
                        
                    buffer += item
                    
                    # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ TTS Ğ¿Ğ¾ÑĞ»Ğµ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ±ÑƒÑ„ĞµÑ€Ğ°
                    if len(buffer) >= TTS_MIN_CHARS and not tts_started:
                        result.tts_start = time.time()
                        tts_started = True
                        await ws.send(json.dumps({"text": buffer, "try_trigger_generation": True}))
                        buffer = ""
                    elif tts_started and len(buffer) >= 20:
                        # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾Ñ€Ñ†Ğ¸ÑĞ¼Ğ¸
                        await ws.send(json.dumps({"text": buffer, "try_trigger_generation": True}))
                        buffer = ""
            
            async def receive_audio():
                """ĞšĞ¾Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼Ğ° Ğ°ÑƒĞ´Ğ¸Ğ¾"""
                nonlocal first_audio
                
                async for msg in ws:
                    try:
                        data = json.loads(msg)
                    except:
                        continue
                        
                    audio_b64 = data.get("audio")
                    if audio_b64:
                        audio_bytes = base64.b64decode(audio_b64)
                        if not first_audio:
                            result.tts_first_audio = time.time()
                            first_audio = True
                        player.enqueue(audio_bytes)
                        
                    if data.get("isFinal"):
                        result.tts_end = time.time()
                        break
            
            # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ Ğ¸ Ğ¿Ñ€Ğ¸Ñ‘Ğ¼ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
            await asyncio.gather(send_text(), receive_audio())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BENCHMARK RUNNERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run_sequential(command: str, llm: StreamingLLM, tts: ElevenLabsTTS, play_audio: bool = True) -> BenchmarkResult:
    """ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²ĞµÑÑŒ LLM, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ TTS"""
    result = BenchmarkResult(input_text=command, mode="sequential")
    player = AudioPlayer()
    
    result.pipeline_start = time.time()
    
    # 1. LLM (Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ)
    text = llm.generate_sync(command, result)
    
    # 2. TTS
    if play_audio:
        player.start()
    await tts.synthesize_text(text, result, player)
    
    # 3. Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ
    if play_audio:
        player.wait_until_done()
        await asyncio.sleep(0.3)
        player.stop()
        
    result.playback_end = time.time()
    return result


async def run_parallel(command: str, llm: StreamingLLM, tts: ElevenLabsTTS, play_audio: bool = True) -> BenchmarkResult:
    """ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼: LLM ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ñ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ² TTS"""
    result = BenchmarkResult(input_text=command, mode="parallel")
    player = AudioPlayer()
    text_queue = asyncio.Queue()
    
    result.pipeline_start = time.time()
    
    async def llm_producer():
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¸ ĞºĞ»Ğ°Ğ´Ñ‘Ñ‚ Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ"""
        for token in llm.generate_stream(command, result):
            await text_queue.put(token)
        await text_queue.put(None)  # Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
    
    if play_audio:
        player.start()
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ LLM Ğ¸ TTS Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾
    await asyncio.gather(
        llm_producer(),
        tts.synthesize_streaming(text_queue, result, player)
    )
    
    # Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ
    if play_audio:
        player.wait_until_done()
        await asyncio.sleep(0.3)
        player.stop()
        
    result.playback_end = time.time()
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run_comparison():
    """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ sequential vs parallel"""
    
    test_commands = [
        "Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹",
        "Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚",
        "ĞºĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°",
        "Ğ·Ğ°ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ",
        "Ğ²ĞºĞ»ÑÑ‡Ğ¸ ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½ĞµÑ€ Ğ½Ğ° 22 Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ°",
    ]
    
    print("=" * 60)
    print("ğŸš€ TTS BENCHMARK V2: Sequential vs Parallel")
    print("=" * 60)
    
    if not ELEVENLABS_API_KEY:
        print("âŒ ELEVENLABS_API_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² .env")
        return
    
    llm = StreamingLLM()
    tts = ElevenLabsTTS()
    
    # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
    llm.warmup()
    
    seq_results = []
    par_results = []
    
    for cmd in test_commands:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ Ğ¢ĞµÑÑ‚: \"{cmd}\"")
        print("=" * 60)
        
        # Sequential
        print("\nâ–¶ï¸ SEQUENTIAL Ñ€ĞµĞ¶Ğ¸Ğ¼...")
        seq_result = await run_sequential(cmd, llm, tts, play_audio=True)
        seq_result.print_report()
        seq_results.append(seq_result)
        
        await asyncio.sleep(1.0)
        
        # Parallel
        print("\nâ–¶ï¸ PARALLEL Ñ€ĞµĞ¶Ğ¸Ğ¼...")
        par_result = await run_parallel(cmd, llm, tts, play_audio=True)
        par_result.print_report()
        par_results.append(par_result)
        
        await asyncio.sleep(1.0)
    
    # Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°
    print("\n" + "=" * 60)
    print("ğŸ“ˆ Ğ¡Ğ’ĞĞ”ĞšĞ Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ¯")
    print("=" * 60)
    
    seq_ttfa = [r.total_ttfa * 1000 for r in seq_results]
    par_ttfa = [r.total_ttfa * 1000 for r in par_results]
    
    print(f"\n{'ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ°':<25} {'Sequential':>12} {'Parallel':>12} {'Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ':>12}")
    print("-" * 60)
    print(f"{'TTFA avg':<25} {sum(seq_ttfa)/len(seq_ttfa):>10.0f}ms {sum(par_ttfa)/len(par_ttfa):>10.0f}ms {(1 - sum(par_ttfa)/sum(seq_ttfa))*100:>10.0f}%")
    print(f"{'TTFA min':<25} {min(seq_ttfa):>10.0f}ms {min(par_ttfa):>10.0f}ms")
    print(f"{'TTFA max':<25} {max(seq_ttfa):>10.0f}ms {max(par_ttfa):>10.0f}ms")
    
    seq_success = sum(1 for t in seq_ttfa if t < 500)
    par_success = sum(1 for t in par_ttfa if t < 500)
    print(f"\n{'TTFA < 500ms':<25} {seq_success}/{len(seq_ttfa):>10} {par_success}/{len(par_ttfa):>10}")


async def run_parallel_only():
    """Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ parallel Ñ€ĞµĞ¶Ğ¸Ğ¼"""
    
    test_commands = [
        "Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚ Ğ² Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ¾Ğ¹",
        "Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ ÑĞ²ĞµÑ‚",
        "ĞºĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°",
        "Ğ·Ğ°ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¿Ğ¸Ñ†Ñ†Ñƒ Ğ¼Ğ°Ñ€Ğ³Ğ°Ñ€Ğ¸Ñ‚Ñƒ",
        "Ğ²ĞºĞ»ÑÑ‡Ğ¸ ĞºĞ¾Ğ½Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½ĞµÑ€ Ğ½Ğ° 22 Ğ³Ñ€Ğ°Ğ´ÑƒÑĞ°",
    ]
    
    print("=" * 60)
    print("ğŸš€ TTS BENCHMARK V2: Parallel Pipeline")
    print("=" * 60)
    
    if not ELEVENLABS_API_KEY:
        print("âŒ ELEVENLABS_API_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² .env")
        return
    
    llm = StreamingLLM()
    tts = ElevenLabsTTS()
    
    llm.warmup()
    
    results = []
    
    for cmd in test_commands:
        print(f"\nğŸ¯ Ğ¢ĞµÑÑ‚: \"{cmd}\"")
        result = await run_parallel(cmd, llm, tts, play_audio=True)
        result.print_report()
        results.append(result)
        await asyncio.sleep(1.0)
    
    # Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°
    print("\n" + "=" * 60)
    print("ğŸ“ˆ Ğ¡Ğ’ĞĞ”ĞšĞ (PARALLEL)")
    print("=" * 60)
    
    ttfa_values = [r.total_ttfa * 1000 for r in results]
    llm_ttft = [r.llm_ttft * 1000 for r in results]
    
    print(f"LLM First Token:    avg={sum(llm_ttft)/len(llm_ttft):.0f}ms")
    print(f"TOTAL TTFA:         avg={sum(ttfa_values)/len(ttfa_values):.0f}ms")
    print(f"                    min={min(ttfa_values):.0f}ms")
    print(f"                    max={max(ttfa_values):.0f}ms")
    
    success_rate = sum(1 for t in ttfa_values if t < 500) / len(ttfa_values) * 100
    print(f"\nâœ… TTFA < 500ms:    {success_rate:.0f}% ({sum(1 for t in ttfa_values if t < 500)}/{len(ttfa_values)})")


async def interactive_mode():
    """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼"""
    print("=" * 60)
    print("ğŸ™ï¸ Ğ˜ĞĞ¢Ğ•Ğ ĞĞšĞ¢Ğ˜Ğ’ĞĞ«Ğ™ Ğ Ğ•Ğ–Ğ˜Ğœ (Parallel Pipeline)")
    print("=" * 60)
    
    if not ELEVENLABS_API_KEY:
        print("âŒ ELEVENLABS_API_KEY Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² .env")
        return
    
    llm = StreamingLLM()
    tts = ElevenLabsTTS()
    
    llm.warmup()
    
    print("\nĞ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ (exit Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°):\n")
    
    while True:
        try:
            command = input("> ").strip()
            if not command:
                continue
            if command.lower() in ["exit", "quit", "q"]:
                break
                
            result = await run_parallel(command, llm, tts, play_audio=True)
            result.print_report()
            
        except KeyboardInterrupt:
            break
            
    print("\nğŸ‘‹ Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!")


def main():
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--interactive":
            asyncio.run(interactive_mode())
        elif sys.argv[1] == "--compare":
            asyncio.run(run_comparison())
        else:
            print("Usage: python tts_benchmark_v2.py [--interactive|--compare]")
    else:
        asyncio.run(run_parallel_only())


if __name__ == "__main__":
    main()
